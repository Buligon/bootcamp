# -*- coding: utf-8 -*-
"""TF2.0 CIFAR10 Improved.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1awhoHscdYdD1d9eJL_rsk1fUTeXXAzX0
"""

import tensorflow as tf

import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, GlobalMaxPooling2D, MaxPooling2D, BatchNormalization
from tensorflow.keras.models import Model

cifar10 = tf.keras.datasets.cifar10

(x_train, y_train), (x_test, y_test) = cifar10.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0
y_train, y_test = y_train.flatten(), y_test.flatten()
print("x_train.shape: ", x_train.shape)
print("y_train.shape: ", y_train.shape)

K = len(set(y_train))
print("number of classes: ", K)

from keras.api._v2.keras import activations
i = Input(shape=x_train[0].shape)
#x = Conv2D(32, (3, 3), strides=2, activation='relu')(i)
#x = Conv2D(64, (3, 3), strides=2, activation='relu')(x)
#x = Conv2D(128, (3, 3), strides=2, activation='relu')(x)

x = Conv2D(32, (3, 3), strides=2, activation='relu', padding='same')(i)
X = BatchNormalization()(x)
x = Conv2D(64, (3, 3), strides=2, activation='relu', padding='same')(x)
X = BatchNormalization()(x)
X = MaxPooling2D((2, 2))(x)
x = Conv2D(32, (3, 3), strides=2, activation='relu', padding='same')(i)
X = BatchNormalization()(x)
x = Conv2D(64, (3, 3), strides=2, activation='relu', padding='same')(x)
X = BatchNormalization()(x)
X = MaxPooling2D((2, 2))(x)
x = Conv2D(32, (3, 3), strides=2, activation='relu', padding='same')(i)
X = BatchNormalization()(x)
x = Conv2D(128, (3, 3), strides=2, activation='relu', padding='same')(x)
X = BatchNormalization()(x)
X = MaxPooling2D((2, 2))(x)
x = Flatten()(x)
x = Dropout(0.2)(x)
x = Dense(1024, activation='relu')(x)
x = Dropout(0.2)(x)
x = Dense(K, activation='softmax')(x)

model = Model(i, x)

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

r = model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=50)

model.save('cifar10_improved.h5')

batch_size = 32
data_generator = tf.keras.preprocessing.image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
train_generator = data_generator.flow(x_train, y_train, batch_size)
steps_per_epoch = x_train.shape[0] // batch_size

r = model.fit(train_generator, validation_data=(x_test, y_test), steps_per_epoch=steps_per_epoch, epochs=50)

model.save('cifar10_improved_augmented.h5')

r = tf.keras.models.load_model('cifar10_improved.h5')
r.evaluate(x_test, y_test)

import matplotlib.pyplot as plt
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='val_loss')
plt.legend()

import matplotlib.pyplot as plt
plt.plot(r.history['accuracy'], label='acc')
plt.plot(r.history['val_accuracy'], label='val_acc')
plt.legend()

model.summary()
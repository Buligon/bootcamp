# -*- coding: utf-8 -*-
"""Detecção de emoção - 01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kYr_tHhmv3-rYRlLuYE4K4KBKDPgJCJu
"""

import cv2
import numpy as np
import pandas as pd
from google.colab.patches import cv2_imshow
import zipfile

import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array

from google.colab import drive
drive.mount('/content/gdrive')

path = "/content/gdrive/My Drive/Material.zip"
zip_object = zipfile.ZipFile(file = path, mode="r")
zip_object.extractall('./')
zip_object.close

imagem = cv2.imread('Material/testes/teste_gabriel.png')
cv2_imshow(imagem)

cascade_faces = 'Material/haarcascade_frontalface_default.xml'
caminho_modelo = "Material/modelo_01_expressoes.h5"
face_detection = cv2.CascadeClassifier(cascade_faces)
classificador_emocoes = load_model(caminho_modelo, compile = False)
expressoes = ['Raiva', 'Nojo', 'Medo', 'Feliz', 'Triste', 'Surpreso', 'Neutro']

original = imagem.copy()
faces = face_detection.detectMultiScale(original, scaleFactor= 1.1,
                                        minNeighbors= 3, minSize = (20, 20))
faces

cinza = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)
cv2_imshow(cinza)

roi = cinza[40:40 + 128, 162:162 + 128]

cv2_imshow(roi)

roi = cv2.resize(roi, (48, 48))

roi = roi.astype('float')

roi = roi / 255 # Deixar valores entre 0 e 1

roi = img_to_array(roi)

roi = np.expand_dims(roi, axis = 0) # necessário aumentar uma dimensão para o tensor flow processar

preds = classificador_emocoes.predict(roi)[0] # pegar apenas a primeira imagem do roi

emotion_probability = np.max(preds)
preds.argmax()

label = expressoes[preds.argmax()]
label

cv2.putText(original, label, (162, 40 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2, cv2.LINE_AA)
cv2.rectangle(original, (162, 40), (162 + 128, 40 + 128), (0, 0, 255), 2)
cv2_imshow(original)

"""# Atividade"""

imagem = cv2.imread('Material/testes/eu.jpeg')
cv2_imshow(imagem)

imagem_og = imagem.copy()
faces = face_detection.detectMultiScale(imagem_og, scaleFactor = 1.1, minNeighbors= 3, minSize= (20, 20))
faces

cinza = cv2.cvtColor(imagem_og, cv2.COLOR_BGR2GRAY)
cinza.shape

roi = cinza[189:189 + 239, 514:514 + 239]
cv2_imshow(roi)

roi = cv2.resize(roi, (48,48))
roi = roi.astype('float')
roi = roi / 255
roi = img_to_array(roi)
roi = np.expand_dims(roi, axis = 0)
roi

preds = classificador_emocoes.predict(roi)[0]

cv2.putText(imagem, expressoes[preds.argmax()], (514 - 10, 189), cv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 0, 255), 2, cv2.LINE_AA)
cv2.rectangle(imagem, (514, 189), (514 + 239,189 + 239), (0, 0, 255), 2)
cv2_imshow(imagem)

"""# Continuação

"""

probabilidades = np.ones((250, 300, 3), dtype='uint8') * 255

if len(faces) == 1:
  for (i, (emotion, prob)) in enumerate(zip(expressoes, preds)):
    # print(i, emotion, prob)
    text = "{}: {:.2f}%".format(emotion, prob * 100)
    w = int(prob * 300)
    cv2.rectangle(probabilidades, (7, (i * 35) + 5), (w, (i * 35) + 35), (200, 250, 20), -1)
    cv2.putText(probabilidades, text, (10, (i * 35) + 23), cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0,0,0), 1, cv2.LINE_AA)
cv2_imshow(probabilidades)